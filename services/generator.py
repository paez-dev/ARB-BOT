"""
ARB-BOT - Generador de Contenido (VersiÃ³n Mejorada)
Modo D: Resumen + Cita textual del RAG
Evita alucinaciones y asegura respuestas verificables.
"""

import logging
import re

logger = logging.getLogger("services.generator")


class ContentGenerator:
    def __init__(self, api_model, text_processor):
        self.api_model = api_model
        self.text_processor = text_processor

    # -----------------------------------------------------------
    # SANITIZACIÃ“N BÃSICA DEL RESUMEN (no borra todo el texto)
    # -----------------------------------------------------------
    def _sanitize_output(self, text: str):
        """Limpia frases de identidad del modelo, pero conserva el contenido Ãºtil."""
        if not text:
            return None

        low = text.lower()

        BLOCKED_PATTERNS = [
            "soy un modelo de lenguaje",
            "como ia",
            "como inteligencia artificial",
            "fui entrenado",
            "no tengo acceso",
            "no tengo la capacidad",
            "mi conocimiento se basa",
        ]

        # En la versiÃ³n nueva, NO eliminamos todo â†’ solo limpiamos la frase
        for pattern in BLOCKED_PATTERNS:
            if pattern in low:
                logger.warning("ğŸŸ¥ Eliminando frase de identidad IA detectada en la respuestaâ€¦")
                text = re.sub(re.escape(pattern), "", text, flags=re.IGNORECASE)

        # quitar dobles espacios si quedaron
        text = re.sub(r"\s+", " ", text).strip()

        return text if text else None

    # -----------------------------------------------------------
    # RESPUESTA ALTERNATIVA SI NO HAY CONTEXTO
    # -----------------------------------------------------------
    def _fallback_response(self, query: str):
        """Cuando no existe contexto en RAG."""
        return (
            "No se encontrÃ³ informaciÃ³n relacionada con tu consulta en los documentos cargados. "
            "Es posible que ese contenido no estÃ© incluido aÃºn. "
            "Puedes intentar otra pregunta o cargar el documento correspondiente."
        )

    # -----------------------------------------------------------
    # FORMATO DE REFERENCIA
    # -----------------------------------------------------------
    def _format_reference(self, metadata):
        """Formatea los metadatos como referencia legible."""
        if not metadata:
            return "ğŸ“ **REFERENCIA**\nManual de Convivencia Escolar Roldanista"
        
        parts = []
        
        # ArtÃ­culo
        if metadata.get("article"):
            parts.append(f"ğŸ“– {metadata['article']}")
        
        # CapÃ­tulo
        if metadata.get("chapter"):
            parts.append(f"ğŸ“‘ {metadata['chapter']}")
        
        # TÃ­tulo
        if metadata.get("title"):
            parts.append(f"ğŸ“š {metadata['title']}")
        
        # ParÃ¡grafo
        if metadata.get("paragraph"):
            parts.append(f"ğŸ“ {metadata['paragraph']}")
        
        # PÃ¡gina
        if metadata.get("page"):
            parts.append(f"ğŸ“„ PÃ¡gina: {metadata['page']}")
        
        if not parts:
            return "ğŸ“ **REFERENCIA**\nManual de Convivencia Escolar Roldanista"
        
        return "ğŸ“ **REFERENCIA**\n" + "\n".join(parts)

    # -----------------------------------------------------------
    # GENERACIÃ“N PRINCIPAL
    # -----------------------------------------------------------
    def generate(self, user_input, max_tokens=512, temperature=0.2, context=None, metadata=None):
        """
        MODO D: RESUMEN + REFERENCIA
        - El modelo genera el resumen basado en el contexto.
        - Se muestra la REFERENCIA (artÃ­culo, capÃ­tulo, pÃ¡gina) en lugar de la cita completa.
        - El usuario puede ir al manual a verificar.
        """

        logger.info(f"ğŸ§© Generando respuesta (Modo D) para: '{user_input}'")

        # Si NO hay contexto â†’ No inventar nada
        if not context:
            logger.warning("âš ï¸ No se suministrÃ³ contexto al generador. Aplicando fallback.")
            return self._fallback_response(user_input)

        # -------------------------------------------------------
        # 1. Prompt para generar SOLO un resumen claro y seguro
        # -------------------------------------------------------
        prompt = (
            "A continuaciÃ³n tienes un fragmento oficial del Manual de Convivencia Escolar Roldanista:\n\n"
            f"Â«{context}Â»\n\n"
            "INSTRUCCIONES IMPORTANTES:\n"
            "- Usa Ãºnicamente la informaciÃ³n presente en el texto anterior.\n"
            "- No inventes informaciÃ³n nueva.\n"
            "- No agregues interpretaciones externas.\n"
            "- No menciones que eres un modelo de lenguaje.\n\n"
            f"Pregunta del usuario: {user_input}\n\n"
            "Genera un resumen claro y fiel al contenido:\n\n"
            "Resumen:"
        )

        # -------------------------------------------------------
        # 2. Llamada al modelo (solo para el resumen)
        # -------------------------------------------------------
        try:
            resumen = self.api_model.generate(
                prompt,
                max_tokens=max_tokens,
                temperature=temperature
            )
        except Exception as e:
            logger.error(f"âŒ Error generando resumen: {e}")
            resumen = None

        # -------------------------------------------------------
        # 3. Limpieza del resumen
        # -------------------------------------------------------
        if resumen:
            resumen = resumen.strip()
            resumen = self._sanitize_output(resumen)

        if not resumen:
            resumen = "No se pudo generar un resumen automÃ¡tico, pero a continuaciÃ³n se muestra el texto exacto."

        # -------------------------------------------------------
        # 4. Detectar si NO encontrÃ³ informaciÃ³n relevante
        # -------------------------------------------------------
        resumen_lower = resumen.lower()
        no_encontro_info = any(frase in resumen_lower for frase in [
            "no se menciona",
            "no se encontrÃ³",
            "no hay informaciÃ³n",
            "no aparece",
            "no estÃ¡ disponible",
            "no se incluye",
            "no contiene informaciÃ³n",
            "no proporciona informaciÃ³n",
            "el fragmento no",
            "el texto no",
        ])

        # -------------------------------------------------------
        # 5. ConstrucciÃ³n de la respuesta final
        # -------------------------------------------------------
        if no_encontro_info:
            # Si no encontrÃ³ info relevante, NO mostrar referencia confusa
            respuesta_final = (
                "ğŸ“Œ **RESUMEN**\n"
                f"{resumen}\n\n"
                "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n\n"
                "â„¹ï¸ Esta informaciÃ³n no se encuentra en el Manual de Convivencia.\n"
                "Puedes consultar directamente con la instituciÃ³n."
            )
        else:
            # Si encontrÃ³ info, mostrar referencia normalmente
            referencia = self._format_reference(metadata)
            respuesta_final = (
                "ğŸ“Œ **RESUMEN**\n"
                f"{resumen}\n\n"
                "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n\n"
                f"{referencia}\n"
            )

        logger.info("ğŸŸ© Respuesta generada exitosamente en Modo D.")
        return respuesta_final
